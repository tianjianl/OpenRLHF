{
  "os":  "Linux-4.18.0-477.27.1.el8_8.x86_64-x86_64-with-glibc2.28",
  "python":  "3.10.15",
  "startedAt":  "2024-11-03T05:27:26.146968Z",
  "args":  [
    "--local_rank=0",
    "--max_len",
    "8192",
    "--dataset",
    "dogtooth/single_pairwise_sft",
    "--input_key",
    "prompt",
    "--output_key",
    "response",
    "--train_batch_size",
    "256",
    "--micro_train_batch_size",
    "1",
    "--max_samples",
    "500000",
    "--pretrain",
    "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "--save_path",
    "/scratch/dkhasha1/tli104/judge_checkpoints/llama31-8b-sft-s+p",
    "--save_steps",
    "400",
    "--logging_steps",
    "1",
    "--eval_steps",
    "-1",
    "--zero_stage",
    "3",
    "--max_epochs",
    "3",
    "--bf16",
    "--flash_attn",
    "--learning_rate",
    "5e-7",
    "--load_checkpoint",
    "--gradient_checkpointing",
    "--apply_chat_template",
    "--tokenizer_chat_template",
    "meta-llama/Meta-Llama-3.1-8B-Instruct-5e-7",
    "--use_wandb",
    "ab0c1974c46fd67412d5b29c5b71ccb5488e0ce7"
  ],
  "program":  "-m openrlhf.cli.train_sft",
  "git":  {
    "remote":  "https://github.com/tianjianl/OpenRLHF",
    "commit":  "284ae688764aa8eb441ee82d32b1b17848d33b92"
  },
  "email":  "litianjian_1998@sina.com",
  "root":  "/weka/home/tli104/OpenRLHF",
  "host":  "c009",
  "username":  "tli104",
  "executable":  "/scratch/dkhasha1/tli104/openrlhf_env/bin/python",
  "cpu_count":  48,
  "cpu_count_logical":  96,
  "gpu":  "NVIDIA A100-SXM4-80GB",
  "gpu_count":  8,
  "disk":  {
    "/":  {
      "total":  "942809059328",
      "used":  "27234791424"
    }
  },
  "memory":  {
    "total":  "1082043854848"
  },
  "cpu":  {
    "count":  48,
    "countLogical":  96
  },
  "gpu_nvidia":  [
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    },
    {
      "name":  "NVIDIA A100-SXM4-80GB",
      "memoryTotal":  "85899345920",
      "cudaCores":  6912,
      "architecture":  "Ampere"
    }
  ],
  "slurm":  {
    "cluster_name":  "cluster",
    "conf":  "/opt/mprov//etc/slurm/slurm.conf",
    "cpus_on_node":  "40",
    "cpus_per_task":  "1",
    "distribution":  "block",
    "gpus_on_node":  "8",
    "grid_setup":  "--partition=a100 --exclude=c001",
    "gtids":  "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39",
    "job_account":  "dkhasha1",
    "job_cpus_per_node":  "40",
    "job_end_time":  "1730639843",
    "job_gid":  "1004",
    "job_id":  "29180",
    "job_name":  "interactive",
    "job_nodelist":  "c009",
    "job_num_nodes":  "1",
    "job_partition":  "a100",
    "job_qos":  "normal",
    "job_start_time":  "1730567843",
    "job_uid":  "1010",
    "job_user":  "tli104",
    "jobid":  "29180",
    "launch_node_ipaddr":  "172.20.3.1",
    "localid":  "0",
    "mem_per_node":  "204800",
    "nnodes":  "1",
    "nodeid":  "0",
    "nodelist":  "c009",
    "nprocs":  "40",
    "ntasks":  "40",
    "prio_process":  "0",
    "procid":  "0",
    "pty_port":  "35507",
    "pty_win_col":  "213",
    "pty_win_row":  "45",
    "srun_comm_host":  "172.20.3.1",
    "srun_comm_port":  "45641",
    "step_gpus":  "0,1,2,3,4,5,6,7",
    "step_id":  "0",
    "step_launcher_port":  "45641",
    "step_nodelist":  "c009",
    "step_num_nodes":  "1",
    "step_num_tasks":  "40",
    "step_tasks_per_node":  "40",
    "stepid":  "0",
    "submit_dir":  "/weka/home/tli104",
    "submit_host":  "ailogin",
    "task_pid":  "333879",
    "tasks_per_node":  "40",
    "topology_addr":  "c009",
    "topology_addr_pattern":  "node",
    "umask":  "0022",
    "working_cluster":  "cluster:mprov-aix:6817:9984:109"
  },
  "cudaVersion":  "12.3"
}